{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"nmnistTrain.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mF7QOb-0g9Xz"},"source":["# Install SlayerPytorch on Colab\n","After the installations the runtime needs to be restarted. \n","```\n","exit()\n","```\n","Will restart the runtime without deleting files. The runtime will automatically start. And if you press \"run all\" the run is not interrupted and works till the end."]},{"cell_type":"code","metadata":{"id":"aSnbF5w-jTGQ"},"source":["!git clone https://github.com/bamsumit/slayerPytorch\n","!pip install ninja\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhdpSnPWkG8r"},"source":["%cd slayerPytorch/\n","!python setup.py install\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7F0vk1qah9Dh"},"source":["Test to verify if everything went well with the installation"]},{"cell_type":"code","metadata":{"id":"35lkjdNJl20b"},"source":["%cd slayerPytorch/test/\n","!python -m  unittest"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YdbSqijZJ59a"},"source":["# SNN configuration"]},{"cell_type":"code","metadata":{"id":"Vm3yReLHsVPU"},"source":["import sys, os\n","CURRENT_TEST_DIR = os.getcwd()\n","sys.path.append(CURRENT_TEST_DIR + \"/../../src\")\n","\n","from datetime import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import slayerSNN as snn\n","#from learningStats import learningStats\n","import zipfile\n","\n","# Dataset definition\n","class nmnistDataset(Dataset):\n","    def __init__(self, datasetPath, sampleFile, samplingTime, sampleLength):\n","        self.path = datasetPath \n","        self.samples = np.loadtxt(sampleFile).astype('int')\n","        self.samplingTime = samplingTime\n","        self.nTimeBins    = int(sampleLength / samplingTime)\n","\n","    def __getitem__(self, index):\n","        inputIndex  = self.samples[index, 0]\n","        classLabel  = self.samples[index, 1]\n","        \n","        inputSpikes = snn.io.read2Dspikes(\n","                        self.path + str(inputIndex.item()) + '.bs2'\n","                        ).toSpikeTensor(torch.zeros((2,34,34,self.nTimeBins)),\n","                        samplingTime=self.samplingTime)\n","        desiredClass = torch.zeros((10, 1, 1, 1))\n","        desiredClass[classLabel,...] = 1\n","        return inputSpikes, desiredClass, classLabel\n","    \n","    def __len__(self):\n","        return self.samples.shape[0]\n","\n","# Network definition\n","class Network(torch.nn.Module):\n","    def __init__(self, netParams):\n","        super(Network, self).__init__()\n","        # initialize slayer\n","        slayer = snn.layer(netParams['neuron'], netParams['simulation'])\n","        self.slayer = slayer\n","        # define network functions\n","        self.conv1 = slayer.conv(2, 16, 5, padding=1)\n","        self.conv2 = slayer.conv(16, 32, 3, padding=1)\n","        self.conv3 = slayer.conv(32, 64, 3, padding=1)\n","        self.pool1 = slayer.pool(2)\n","        self.pool2 = slayer.pool(2)\n","        self.fc1   = slayer.dense((8, 8, 64), 10)\n","\n","    def forward(self, spikeInput):\n","        spikeLayer1 = self.slayer.spike(self.conv1(self.slayer.psp(spikeInput ))) # 32, 32, 16\n","        spikeLayer2 = self.slayer.spike(self.pool1(self.slayer.psp(spikeLayer1))) # 16, 16, 16\n","        spikeLayer3 = self.slayer.spike(self.conv2(self.slayer.psp(spikeLayer2))) # 16, 16, 32\n","        spikeLayer4 = self.slayer.spike(self.pool2(self.slayer.psp(spikeLayer3))) #  8,  8, 32\n","        spikeLayer5 = self.slayer.spike(self.conv3(self.slayer.psp(spikeLayer4))) #  8,  8, 64\n","        spikeOut    = self.slayer.spike(self.fc1  (self.slayer.psp(spikeLayer5))) #  10\n","\n","        return spikeOut"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LbZQ0ynb3hz"},"source":["import time\n","import shutil\n","\n","def save_ckp(state, is_best_loss, is_best_acc, checkpoint_dir, best_model_dir):\n","    f_path = checkpoint_dir+'checkpoint.pt'\n","    torch.save(state, f_path)\n","    if is_best_loss:\n","        best_fpath = best_model_dir+'best_model.pt'\n","        shutil.copyfile(f_path, best_fpath)\n","    if is_best_acc:\n","        acc_fpath =  best_model_dir+'best_acc.pt'\n","        shutil.copyfile(f_path, acc_fpath)\n","        \n","def load_ckp(checkpoint_fpath, model, optimizer):\n","    checkpoint = torch.load(checkpoint_fpath)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer, checkpoint['epoch']\n","\n","\n","# Read SNN configuration from yaml file\n","netParams = snn.params('/content/slayerPytorch/exampleLoihi/02_NMNIST/network.yaml')\n","\n","# Ts   = netParams['simulation']['Ts']\n","# Ns   = int(netParams['simulation']['tSample'] / netParams['simulation']['Ts'])\n","# Nin  = int(netParams['layer'][0]['dim'])\n","# Nhid = int(netParams['layer'][1]['dim'])\n","# Nout = int(netParams['layer'][2]['dim'])\n","\n","# Extract NMNISTsmall dataset\n","with zipfile.ZipFile('/content/slayerPytorch/exampleLoihi/02_NMNIST/NMNISTsmall.zip') as zip_file:\n","    for member in zip_file.namelist():\n","        if not os.path.exists('./' + member):\n","            zip_file.extract(member, './')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSGWaF7LLnGC"},"source":["#Training Loop\n","Train the SNN and saves a checkpoint"]},{"cell_type":"code","metadata":{"id":"9mH_-npUsFDh"},"source":["if __name__ == '__main__':\n","\n","    # Define the cuda device to run the code on.\n","    device = torch.device('cuda')\n","    # Use multiple GPU's if available\n","    # device = torch.device('cuda:2') # should be the first GPU of deviceIDs\n","    # deviceIds = [2, 3, 1]\n","\n","    # Create network instance.\n","    net = Network(netParams).to(device)\n","    # Split the network to run over multiple GPUs\n","    # net = torch.nn.DataParallel(Network(netParams).to(device), device_ids=deviceIds)\n","\n","    # Create snn loss instance.\n","    error = snn.loss(netParams).to(device)\n","\n","    # Define optimizer module.\n","    optimizer = torch.optim.Adam(net.parameters(), lr = 0.01, amsgrad = True)\n","\n","    # Dataset and dataLoader instances.\n","    trainingSet = nmnistDataset(datasetPath =netParams['training']['path']['in'], \n","                                sampleFile  =netParams['training']['path']['train'],\n","                                samplingTime=netParams['simulation']['Ts'],\n","                                sampleLength=netParams['simulation']['tSample'])\n","    trainLoader = DataLoader(dataset=trainingSet, batch_size=12, shuffle=False, num_workers=4)\n","\n","    testingSet = nmnistDataset(datasetPath  =netParams['training']['path']['in'], \n","                                sampleFile  =netParams['training']['path']['test'],\n","                                samplingTime=netParams['simulation']['Ts'],\n","                                sampleLength=netParams['simulation']['tSample'])\n","    testLoader = DataLoader(dataset=testingSet, batch_size=12, shuffle=False, num_workers=4)\n","\n","    # Learning stats instance.\n","    stats = learningStats()\n","\n","    # training loop\n","    for epoch in range(100):\n","        tSt = datetime.now()\n","        \n","        # Training loop.\n","        for i, (input, target, label) in enumerate(trainLoader, 0):\n","            # Move the input and target to correct GPU.\n","            input  = input.to(device)\n","            target = target.to(device) \n","            \n","            # Forward pass of the network.\n","            output = net.forward(input)\n","            \n","            # Gather the training stats.\n","            stats.training.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","            stats.training.numSamples     += len(label)\n","            \n","            # Calculate loss.\n","            loss = error.numSpikes(output, target)\n","            \n","            # Reset gradients to zero.\n","            optimizer.zero_grad()\n","            \n","            # Backward pass of the network.\n","            loss.backward()\n","            \n","            # Update weights.\n","            optimizer.step()\n","\n","            # Gather training loss stats.\n","            stats.training.lossSum += loss.cpu().data.item()\n","\n","            # Display training stats.\n","            stats.print(epoch, i, (datetime.now() - tSt).total_seconds())\n","\n","        # Testing loop.\n","        # Same steps as Training loops except loss backpropagation and weight update.\n","        for i, (input, target, label) in enumerate(testLoader, 0):\n","            input  = input.to(device)\n","            target = target.to(device) \n","            \n","            output = net.forward(input)\n","\n","            stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","            stats.testing.numSamples     += len(label)\n","\n","            loss = error.numSpikes(output, target)\n","            stats.testing.lossSum += loss.cpu().data.item()\n","            stats.print(epoch, i)\n","        \n","        # Update stats.\n","        stats.update()\n","        checkpoint={\n","          'epoch': epoch+1,\n","          'state_dict':net.state_dict(),\n","          'optimizer': optimizer.state_dict()}\n","        save_ckp(checkpoint,stats.training.bestLoss, stats.testing.bestAccuracy,'./', './')\n"],"execution_count":null,"outputs":[]}]}