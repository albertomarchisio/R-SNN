{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DVS128GesturePreprocessor.ipynb","provenance":[],"collapsed_sections":["mF7QOb-0g9Xz","3VznTeL0iuNs","KkXiMZTmj6W6"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mF7QOb-0g9Xz"},"source":["# Install SlayerPytorch on Colab\n","After the installations the runtime needs to be restarted. \n","```\n","exit()\n","```\n","Will restart the runtime without deleting files. The runtime will automatically start. And if you press \"run all\" the run is not interrupted and works till the end."]},{"cell_type":"code","metadata":{"id":"aSnbF5w-jTGQ"},"source":["!git clone https://github.com/bamsumit/slayerPytorch\n","!pip install dv\n","!pip install ninja\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhdpSnPWkG8r"},"source":["%cd slayerPytorch/\n","!python setup.py install\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7F0vk1qah9Dh"},"source":["Test to verify if everything went well with the installation"]},{"cell_type":"code","metadata":{"id":"35lkjdNJl20b"},"source":["%cd slayerPytorch/test/\n","!python -m  unittest"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3VznTeL0iuNs"},"source":["# Get the dataset\n","Download the dataset from [here](https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8).\n","Be careful to select the right path when you unzip the files."]},{"cell_type":"code","metadata":{"id":"jiAYSYo6oz5l"},"source":["!unzip './DVSGesturedataset.zip' -d /content/slayerPytorch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KkXiMZTmj6W6"},"source":["# Pre-process the dataset\n","Every sample contains all the actions performed in sequence by a subject. This program is able to divide the samples into smaller ones, containing single actions.\n"]},{"cell_type":"code","metadata":{"id":"1HBUYAmLqagO"},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import slayerSNN as snn\n","from dv import LegacyAedatFile\n","\n","path = '/content/slayerPytorch/DVSGesturedataset/DvsGesture/'\n","\n","actionName = [\n","    'hand_clapping',\n","    'right_hand_wave',\n","    'left_hand_wave',\n","    'right_arm_clockwise',\n","    'right_arm_counter_clockwise',\n","    'left_arm_clockwise', \n","    'left_arm_counter_clockwise',\n","    'arm_roll',\n","    'air_drums',\n","    'air_guitar',\n","    'other_gestures',\n","]\n","\n","def readAedatEvent(filename):\n","    xEvent = []\n","    yEvent = []\n","    pEvent = []\n","    tEvent = []\n","    with LegacyAedatFile(filename) as f:\n","        for event in f:\n","            xEvent.append(event.x)\n","            yEvent.append(event.y)\n","            pEvent.append(event.polarity)\n","            tEvent.append(event.timestamp/1000)\n","\n","    return xEvent, yEvent, pEvent, tEvent\n","\n","    def splitData(filename, path):\n","    x,y,p,t = readAedatEvent(path+filename+'.aedat')\n","    labels = np.loadtxt(path + filename + '_labels.csv', delimiter=',', skiprows=1)\n","    labels[:,0]  -= 1\n","    labels[:,1:]\n","    if not os.path.isdir(path+ 'data/' + filename):\n","        os.makedirs(os.path.join(path,'data/' + filename))\n","    lastAction = 100\n","    for action, tst, ten in labels:\n","        if action == lastAction:    continue # This is to ignore second arm_roll samples\n","        print(actionName[int(action)])\n","        ind = (t >= tst/1000) & (t < ten/1000)\n","        ind_in = np.argmax(ind)\n","        ind_end = ind_in+np.argmin(ind[(ind.argmax()):-1])\n","        if ind_end == ind_in:\n","          ind_end = 0\n","        TD = snn.io.event(x[ind_in:ind_end-1], y[ind_in:ind_end-1], p[ind_in:ind_end-1], (t[ind_in:ind_end-1] - tst/1000))\n","        # snn.io.showTD(TD)\n","        lastAction = action\n","\n","        snn.io.encodeNpSpikes(path+'data/'+ filename + '/{:g}.npy'.format(action), TD)\n","\n","   \n","if __name__ == '__main__':\n","    user = np.arange(29) + 1\n","    lighting = [\n","        'fluorescent',\n","        'fluorescent_led',\n","        'lab',\n","        'led',\n","        'natural',\n","    ]\n","    count = 0\n","    for id in user:\n","        for light in lighting:\n","            filename = 'user{:02d}_{}'.format(id, light)\n","            if os.path.isfile(path + filename + '.aedat'):\n","                print(count, filename)\n","                splitData(filename, path)\n","                count += 1"],"execution_count":null,"outputs":[]}]}